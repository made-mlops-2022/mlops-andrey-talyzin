apiVersion: apps/v1
kind: Deployment
metadata:
  name: online-inference-deployment-rolling-update
  labels:
    app: online-inference
spec:
  replicas: 3
  selector:
    matchLabels: 
      app: online-inference
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      name: online-inference-deployment-rolling-update
      labels:
        app: online-inference
    spec:
      containers:
        - name: online-inference
          image: rtmlrtx/online-inference:v1
          ports:
            - containerPort: 8080
          resources:
            requests:
              memory: "1Gi"
              cpu: "200m"
            limits:
              memory: "5Gi"
              cpu: "500m"